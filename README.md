## 使用 NodeJs 爬取网站电影(腾讯视频)、音乐、表情包等数据

### 爬虫又称网络机器人，是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本；通俗的讲就是模拟人进行浏览器操作。

### 特此声明：此功能仅作为node入门学习，不涉及任何商业目的

### 目录结构
```bash
├── emoticon                   # 爬取表情包模块
├── movie                      # 爬取电影模块
    ├── movies                 # 保存网站所有电影数据的目录
    │   │── 地区                # 地区分类下的所有数据
    │   │── 类型                # 类型分类下的所有数据
    │   │── 年份                # 年份分类下的所有数据
    │   │── 排序                # 排序分类下的所有数据
    │   └── 特色                # 特色分类下的所有数据
    ├── index.js               # 入口文件，爬取所有电影数据
    ├── movies.js              # 封装的爬虫方法
    └── server.js              # 启动web服务，输出数据到页面
├── music                      # 爬取音乐模块
├── progress-bar.js            # 封装的控制台打印方法
├── tool-fs                    # 对fs进行二次封装
└── package.json               # package.json 依赖
```


### 电影模块（可能会因为网站更新导致抓取失败，只需修改正则匹配部分代码即可）

#### 需要用到的包：
1. request: 服务端请求；
2. single-line-log： 控制台打印抓取进度


#### 大致思路(音乐，表情包通用)：
1. 进入所有电影页，复制url，使用request请求该url拿到页面所有数据；
2. 抓取每一个分类部分代码，进行正则匹配，拿到每一个分类的url；
3. 请求上一步url的页面数据，可以匹配改页面的所有电影列表数据，抓取所有电影信息；
4. 有部分字段需要在电影的详情页中抓取，请求上一步中抓取到的url获取详情页数据，使用正则匹配获取详情字段；
5. 第二步中可以使用循环遍历抓取每一页的数据；
6. 封装第二部方法，再次循环遍历所有类型，如：排序，类型，地区，特色，年份等以抓取网站全部数据；
7. 最后，使用node提供的文件系统，将所有数据保存在本地文件。

#### 重点解析
一、 正则匹配：
1. 修饰符：s   
由于 **.** 默认不匹配换行符，所以要使用修饰符 **s** 来匹配任何字符（包括终止符 '\n'）

2. exec使用：  
该函数返回一个类数组，其中存放匹配的结果，如果未找到匹配，则返回值为 null。

``` js
/(.*?)e/.exec("The best things in life are free!");

=> [
  0: "The"
  1: "Th"
  groups: undefined
  index: 0
  input: "The best thin
]

// 0：匹配的整个单词
// 1：要匹配的部分
// index: 匹配字符串中对应字符的位置

```
需要循环遍历exec方法，才能抓取到所有要匹配的数据。


### 表情包模块

#### 需要用到的包
cheerio：nodejs的抓取页面模块，为服务器特别定制的，快速、灵活、实施的jQuery核心实现。适合各种web爬虫程序
axios: 服务端请求；

#### 大致思路
1. 复制分类页面地址，使用axios请求该页数据
2. 使用cheerio的方式抓取表情包名称及详情页地址
3. 使用上一步拿到的地址请求详情页数据
4. 抓取详情页所有表情
5. 根据第二部创建对应的表情包目录，将第四步中的表情(使用axios请求url，并设置响应数据类型为stream)使用流的方式生成文件保存在本地

### 音乐模块